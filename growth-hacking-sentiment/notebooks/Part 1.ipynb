{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902348f6-36d7-44c2-ae02-431948583f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LARGE_DATASET_SIZE = 100000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b52ca3f-17a3-4284-8134-207becfa5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_csv(df: pd.DataFrame, filename: str):\n",
    "    df = df[['reviewText', 'overall']]\n",
    "    df = df.rename({'reviewText': 'reviews', 'overall': 'ratings'})\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95d7263-63b3-4303-9f2c-27bb66f9b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/Video_Games_5.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ca817-6c11-4b04-9e5b-d6f88de74205",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar().encode(\n",
    "   x='overall', y='count()'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2db46-ee4f-4ad4-8684-d0984d5e9741",
   "metadata": {},
   "source": [
    "So the thing with Machine Learning, is that generally training works best with balanced datasets - i.e. there is an equal number of rows in each category. Otherwise the model might start to see a bias. e.g. if 90% of rows are 5 star reviews, then it might just claim every review is 5 star regardless of the actual sentiment. Some models are more resistant to this bias than others. Decision trees/random forests deal with imbalanced data well. This article explains the problem - https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "\n",
    "For other types of model, one solution is to create a balanced training dataset. This can be done by either adding rows or removing rows in a particular category.\n",
    "\n",
    "Oversampling, we means increasing rows by including the same row more than once.\n",
    "Synthetic Minority Oversampling Technique (SMOTE) creates synthetic extra rows to add by using a nearest neighbours algorithm.\n",
    "Undersampling, means dropping rows. This works well when there is a large dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb69ffa-db48-4a80-9f64-2d951bdf228c",
   "metadata": {},
   "source": [
    "# Data format\n",
    "\n",
    "* \"overall\" - score. Integer [1..5]\n",
    "* \"verified\" - Has the review been verified. Boolean\n",
    "* \"reviewerID\" - Unique identifier for the review. String.\n",
    "* \"asin\" - Unknown. String\n",
    "* \"reviewTime\" - Date of review. Date format \"MM DD, YYYY\"\n",
    "* \"reviewerName\" - Name of the reviewer. String\n",
    "* \"reviewText\" - The review. String\n",
    "* \"summary\" - Summary of the review. String.\n",
    "* \"unixReviewTime\" - Timestamp for review. Unix Epoch format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed02dee-bc74-424e-8167-0b4044abe868",
   "metadata": {},
   "source": [
    "# Create and save small balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99cc2c1-fd2d-491e-b1de-93bfa22fda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {1: 1500, 2: 500, 3: 500, 4: 500, 5: 1500}\n",
    "under_sampler = RandomUnderSampler(sampling_strategy=strategy, random_state=RANDOM_SEED)\n",
    "small_df, _ = under_sampler.fit_resample(df, df['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379b755-326c-4b84-aa7e-25024436d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(small_df).mark_bar().encode(\n",
    "   x='overall', y='count()'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3b5756-1689-42e4-b8c6-8ec3c0fe75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_to_csv(small_df, '../data/small_corpus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e727d-2b13-4528-b90e-765ecd61b906",
   "metadata": {},
   "source": [
    "# Create and save large unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1c2b89-955a-4c80-91f9-ef7a49b6afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=RANDOM_SEED)\n",
    "random_indexes = np.random.randint(0, len(df), LARGE_DATASET_SIZE)\n",
    "large_df = df.iloc[random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fd760-f29e-4340-8a2c-0fff39147749",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(large_df).mark_bar().encode(\n",
    "   x='overall', y='count()'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a49588-a094-4ee3-923b-bba73219cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_to_csv(large_df, '../data/large_corpus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
